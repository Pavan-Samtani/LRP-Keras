{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tfUtils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense, Flatten, ZeroPadding2D, Conv2D, BatchNormalization, MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(m, n_x, seed = 9):\n",
    "    np.random.seed = seed\n",
    "    X = np.random.randn(m, n_x)\n",
    "    Y = np.zeros((m, 2))\n",
    "    dist = np.random.randint(low = 0, high = n_x-1, size = m)\n",
    "    for i in range(m):\n",
    "        t = np.random.rand();\n",
    "        if t < 0.5:\n",
    "            X[i, dist[i]] = -20\n",
    "            Y[i, 0] = 1\n",
    "        elif t >= 0.5:\n",
    "            X[i, dist[i]] = 20\n",
    "            Y[i, 1] = 1\n",
    "    return X, Y, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(shape, name, which):\n",
    "    if which == \"weights\":\n",
    "        return tf.get_variable(name, shape, \n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "    elif which == \"bias\":\n",
    "        return tf.get_variable(name, shape, \n",
    "                              initializer = tf.zeros_initializer())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_h, n_w, n_c, n_y):\n",
    "    X = tf.placeholder(tf.float32, [None, n_h, n_w, n_c])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(layer):\n",
    "    size = layer.shape\n",
    "    num_features = size[1] * size[2] * size[3]\n",
    "    flattened_layer = tf.reshape(layer, [-1, num_features])\n",
    "    return flattened_layer, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(layer, input_features, output_features, activation, indicator):\n",
    "    weights = initialize_parameters([input_features, output_features], \"W\" + str(indicator), \"weights\")\n",
    "    bias = initialize_parameters([1, output_features], \"b\" + str(indicator), \"bias\")\n",
    "    Z = tf.matmul(layer, weights) + bias\n",
    "    if activation == \"relu\":\n",
    "        return tf.nn.relu(Z), weights, bias\n",
    "    elif activation == \"sigmoid\":\n",
    "        return tf.nn.sigmoid(Z), weights, bias\n",
    "    elif activation == \"tanh\":\n",
    "        return tf.nn.tanh(Z), weights, bias\n",
    "    elif activation == \"linear\":\n",
    "        return Z, weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2D(layer, filter_size, output_channels, stride, padding, activation, use_maxpool, indicator):\n",
    "    input_channels = layers.shape[3]\n",
    "    weights = initialize_parameters([filter_size, filter_size, input_channels, output_channels], \"W\" + str(indicator), \n",
    "                                   \"weights\")\n",
    "    bias = initialize_parameters([output_channels], \"b\" + str(indicator), \"bias\")\n",
    "    Z = tf.nn.conv2d(layer, weights, strides = [1, stride, stride, 1], padding = padding) + bias\n",
    "    if activation == \"relu\":\n",
    "        A = tf.nn.relu(Z)\n",
    "    elif activation == \"sigmoid\":\n",
    "        A = tf.nn.sigmoid(Z)\n",
    "    elif activation == \"tanh\":\n",
    "        A = tf.nn.tanh(Z)\n",
    "    elif activation == \"linear\":\n",
    "        A = Z\n",
    "    if use_maxpool:\n",
    "        return tf.nn.max_pool(A, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID'), weights, bias\n",
    "    else:\n",
    "        return A, weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z, labels = Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, dist = generate_data(50000, 144)\n",
    "X_train = X_train.reshape(-1, 12, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, layers, filter_size, stride, padding, activation, \n",
    "          use_maxpool, epochs, batch_size, starting_rate, decay):\n",
    "    input_shape = X.shape\n",
    "    output_shape = Y.shape\n",
    "    X, Y = create_placeholders(input_shape[1], input_shape[2], input_shape[3], output_shape[1])\n",
    "    parameters = {}\n",
    "    A = X\n",
    "    already_flat = 0\n",
    "    for i in range(1, len(layers) + 1):\n",
    "        if layers[i][0] == 'conv_2D':\n",
    "            A, parameters['W' + str(i)], parameters['b' + str(i)] = conv_2D(\n",
    "                A, filter_size, layers[i - 1], stride, padding, activation[i - 1], use_maxpool, indicator = i)\n",
    "        elif layers[i][0] == 'fc':\n",
    "            if already_flat == 0:\n",
    "                A, input_layers = flatten(A)\n",
    "            else: input_layers = A.get_shape()[1]\n",
    "            A, parameters['W' + str(i)], parameters['b' + str(i)] = fully_connected(\n",
    "                A, input_layers, layers[i - 1], activation[i - 1], indicator = i)\n",
    "    cost = compute_cost(A, Y)\n",
    "    hard_A = tf.argmax(tf.nn.softmax(A, axis = 1), axis = 1)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(hard_A, tf.argmax(Y, axis = 1)), tf.float32))\n",
    "    global_steps = tf.Variable(0, trainable = False)\n",
    "    learning_rate = tf.train.exponential_decay(starting_rate, global_steps, 5000, decay, staircase = True)\n",
    "    train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost, global_step = global_steps)\n",
    "    init = tf.global_variables_initializer()\n",
    "    cost_list = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(epochs):\n",
    "            minibatches = random_minibatches(X_train, Y_train, batch_size, seed = epoch)\n",
    "            epoch_cost = 0\n",
    "            for minibatch in minibatches:\n",
    "                sess.run(train, feed_dict = {X : minibatch[0], Y : minibatch[1]})\n",
    "                epoch_cost += sess.run(cost, feed_dict = {X : minibatch[0], Y : minibatch[1]}) / len(minibatches)\n",
    "            cost_list.append(epoch_cost)        \n",
    "            if epoch % 5 == 0:\n",
    "                print(epoch_cost)\n",
    "        parameter_names = []\n",
    "        parameter_list = []\n",
    "        for i in range(1, len(parameters) / 2 + 1):\n",
    "            parameter_names.append(\"W\" + str(i))\n",
    "            parameter_names.append(\"b\" + str(i))\n",
    "        for j in range(len(parameter_names)):\n",
    "            parameter_list.append(sess.run(parameters[parameter_names[j]]))\n",
    "        print(\"accuracy\", sess.run(acc, feed_dict = {X : X_train, Y : Y_train}))\n",
    "    sess.close()\n",
    "    plt.plot(np.array(cost_list), '-b')\n",
    "    plt.show()\n",
    "    return parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
